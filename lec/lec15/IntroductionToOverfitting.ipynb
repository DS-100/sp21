{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Overfitting\n",
    "\n",
    "\n",
    "One of the key challenges with feature engineering is that you can \"over engineer\" your features and produce a model that fits the data but performs poorly when making predictions on new data.  This is typically referred to as **overfitting** to your data and is the focus on the next set of lectures.  \n",
    "\n",
    "In this notebook, we will provide a very simple illustration of overfitting, but as you will see and soon experience, it is very easy to overfit to your data and this will become the key challenge in the design of good models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Toy Data and Model Setup\n",
    "\n",
    "For this problem we will use a very simple toy dataset to help illustrate where things will fail.  \n",
    "\n",
    "**Notice** that there are only 8 datapoints in this dataset.  Small data is especially prone to the challenges of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/train.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = px.colors.qualitative.Plotly\n",
    "data_scatter = go.Scatter(x=data[\"X\"], y=data[\"Y\"], name=\"data\", mode=\"markers\", \n",
    "                          marker=dict(color=colors[0]))\n",
    "go.Figure([data_scatter])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "## Fit a Basic Linear Model\n",
    "\n",
    "We can start by fitting a basic linear model to the data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(data[[\"X\"]], data[\"Y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before we define a helper routine to track our progress in model design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, model, phi, models=dict()):\n",
    "    # run the prediction function and compute the RMSE\n",
    "    Yhat = model.predict(phi(data[[\"X\"]].to_numpy()) ).flatten()\n",
    "    Y = data['Y'].to_numpy()\n",
    "    rmse = np.sqrt(mean_squared_error(Y, Yhat))\n",
    "    print(\"Root Mean Squared Error:\", rmse)\n",
    "    \n",
    "    # Save the model and rmse to the collection of models \n",
    "    models[name] = dict(model=model, phi=phi, rmse=rmse)\n",
    "    \n",
    "    # Generate diagnostic and model comparison plots\n",
    "    fig = make_subplots(rows=1, cols=2)\n",
    "    fig.add_trace(data_scatter, row=1, col=1)    \n",
    "    xgrid = np.expand_dims(np.linspace(-3, 1.4, 100),1)\n",
    "    for (i,m) in enumerate(models):\n",
    "        fig.add_trace(go.Scatter(x=xgrid.flatten(), \n",
    "            y=models[m][\"model\"].predict(models[m][\"phi\"](xgrid)).flatten(), \n",
    "                                 marker=dict(color=colors[i+2]),\n",
    "                                 name=m), row=1, col=1)\n",
    "    fig.update_xaxes(title = \"X\", row=1, col=1)\n",
    "    fig.update_yaxes(title = \"Y\", range=[0,10], row=1, col=1)\n",
    "    fig.add_trace(go.Bar(x=list(models.keys()), \n",
    "                         y=[models[k]['rmse'] for k in models], \n",
    "                         marker=dict(color=colors[0]), showlegend=False), row=1, col=2)    \n",
    "    fig.update_yaxes(title = \"RMSE\", row=1, col=2)\n",
    "    fig.show()\n",
    "\n",
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(\"Linear in X\", model, lambda x: x, models )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over Engineering\n",
    "\n",
    "How could we improve the model fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_polynomials(x, p=3):\n",
    "    return np.hstack([x**i for i in range(1,p+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_polynomials(np.array([[1],[2],[3],[4],[5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(phi_polynomials(data[[\"X\"]].to_numpy(), p=2), data[[\"Y\"]])\n",
    "evaluate_model(\"Quadratic\", model, lambda x: phi_polynomials(x, p=2), models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(phi_polynomials(data[[\"X\"]].to_numpy(), p=3), data[[\"Y\"]])\n",
    "evaluate_model(\"Cubic\", model, lambda x: phi_polynomials(x, p=3), models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(phi_polynomials(data[[\"X\"]].to_numpy(), p=4), data[[\"Y\"]])\n",
    "evaluate_model(\"Quartic\", model, lambda x: phi_polynomials(x, p=4), models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(phi_polynomials(data[[\"X\"]].to_numpy(), p=5), data[[\"Y\"]])\n",
    "evaluate_model(\"Quintic\", model, lambda x: phi_polynomials(x, p=5), models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(phi_polynomials(data[[\"X\"]].to_numpy(), p=8), data[[\"Y\"]])\n",
    "evaluate_model(\"Octic\", model, lambda x: phi_polynomials(x, p=8), models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Success!?\n",
    "\n",
    "What happens if we get more data from the world?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"data/test.csv\")\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting this new data (in red) on top of the old data we see that while the more complex RBF model fit the original data perfectly, it does not fit the new "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_scatter = go.Scatter(name = \"Test Data\", x = test_data['X'], y = test_data['Y'], \n",
    "                       mode = 'markers', marker=dict(symbol=\"cross\", color=colors[1]))\n",
    "go.Figure([data_scatter, test_data_scatter])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we plot this data on top of our previous picture?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def better_evaluate_model(name, model, phi, models=dict()):\n",
    "    \n",
    "    # Save the model and rmse to the collection of models \n",
    "    models[name] = dict(model=model, phi=phi)\n",
    "    \n",
    "    # Generate diagnostic and model comparison plots\n",
    "    fig = make_subplots(rows=1, cols=2)\n",
    "    fig.add_trace(data_scatter, row=1, col=1)    \n",
    "    fig.add_trace(test_data_scatter, row=1, col=1)    \n",
    "    xgrid = np.expand_dims(np.linspace(-4, 3, 100),1)\n",
    "    for (i,m) in enumerate(models):\n",
    "        model = models[m][\"model\"]\n",
    "        phi = models[m][\"phi\"]\n",
    "        # run the prediction function and compute the RMSE\n",
    "        fig.add_trace(go.Scatter(x=xgrid.flatten(), \n",
    "            y=model.predict(phi(xgrid)).flatten(), \n",
    "                                 marker=dict(color=colors[i+2]),\n",
    "                                 name=m), row=1, col=1)\n",
    "        if \"train_rmse\" not in models[m]:\n",
    "            # Evaluate train and test \n",
    "            Yhat_train = model.predict(phi(data[[\"X\"]].to_numpy()) ).flatten()\n",
    "            Y_train = data['Y'].to_numpy()\n",
    "            models[m]['train_rmse'] = np.sqrt(mean_squared_error(Y_train, Yhat_train))\n",
    "        \n",
    "            Yhat_test = model.predict(phi(test_data[[\"X\"]].to_numpy()) ).flatten()\n",
    "            Y_test = test_data['Y'].to_numpy()\n",
    "            models[m]['test_rmse'] = np.sqrt(mean_squared_error(Y_test, Yhat_test))\n",
    "        \n",
    "    fig.update_xaxes(title = \"X\", row=1, col=1)\n",
    "    fig.update_yaxes(title = \"Y\", range=[0,10], row=1, col=1)\n",
    "    fig.add_trace(go.Bar(x=list(models.keys()), \n",
    "                         y=[models[k]['train_rmse'] for k in models], \n",
    "                         marker=dict(color=colors[0]), name=\"Training Error\"), row=1, col=2)    \n",
    "    fig.add_trace(go.Bar(x=list(models.keys()), \n",
    "                         y=[models[k]['test_rmse'] for k in models], \n",
    "                         marker=dict(color=colors[1]), name=\"Testing Error\"), row=1, col=2)    \n",
    "    fig.update_yaxes(title = \"RMSE\", row=1, col=2)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plots the training and test error.  Try zooming in to see what happens to training error and testing error as we increase the number of features in our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(phi_polynomials(data[[\"X\"]].to_numpy(), p=8), data[[\"Y\"]])\n",
    "better_evaluate_model(\"Octic\", model, lambda x: phi_polynomials(x, p=8), models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the rest of this lecture we will dig into the ideas drive this behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's happening: _Over-fitting_\n",
    "\n",
    "As we increase the expressiveness of our model we begin to **over-fit** to the variability in our training data.  That is we are learning patterns that do not **generalize** beyond our training dataset\n",
    "\n",
    "**Over-fitting** is a key challenge in machine learning and statistical inference.  At it's core is a fundamental trade-off between **bias** and **variance**: _the desire to explain the training data and yet be robust to variation in the training data_.\n",
    "\n",
    "We will study the **bias-variance** trade-off in today's lecture.\n",
    "\n",
    "<img src=\"images/under_over_fitting.png\" width=\"500px\">\n",
    "\n",
    "---\n",
    "\n",
    "<br/><br/><br/><br/><br/><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
