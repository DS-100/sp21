{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adjusted-scout",
   "metadata": {},
   "source": [
    "# Homework 7: Predicting Housing Prices - Build Your Own Model\n",
    "\n",
    "## Due Date: 11:59pm Thursday, March 25th\n",
    "\n",
    "## You are not required to complete this notebook nor will you be graded on this part -- this only serves as a guide to simplify the process of submitting your model predictions for the contest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-pathology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Imports You Might Need\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import linear_model as lm\n",
    "\n",
    "# Plot settings\n",
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Extract Dataset\n",
    "with zipfile.ZipFile('cook_county_contest_data.zip') as item:\n",
    "    item.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "steady-avatar",
   "metadata": {},
   "source": [
    "### Note\n",
    "\n",
    "This notebook is specifically designed to guide you through the process of exporting your model's predictions on the test dataset for submission so you can see how your model stacks up against others'. \n",
    "\n",
    "Most of what you have done in question 8 of Homework 7 should be transferrable here. However, there are a few small changes you will need to make on your part to make sure the function meets our requirements, so **please read the following instructions very carefully**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-credit",
   "metadata": {},
   "source": [
    "## Step 1. Set up all the helper functions for your `process_data_fm` function.\n",
    "\n",
    "**Copy-paste all of the helper functions your `process_data_fm` need here in the following cell**. Note that we have provided you with the skeletons for some of the feature engineering functions we asked you to implement in the assignment below, but feel free to also add more of your own functions. You **do not** have to fill out all of the functions in the cell below -- only fill out those that are actually useful to your feature engineering pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-breathing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_total_bedrooms(data):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      data (data frame): a data frame containing at least the Description column.\n",
    "    \"\"\"\n",
    "    with_rooms = data.copy()\n",
    "    ...\n",
    "    return with_rooms\n",
    "\n",
    "def ohe_roof_material(data):\n",
    "    \"\"\"\n",
    "    One-hot-encodes roof material.  New columns are of the form 0x_QUALITY.\n",
    "    \"\"\"\n",
    "    ...\n",
    "    \n",
    "def process_data_gm(data, pipeline_functions, prediction_col):\n",
    "    \"\"\"Process the data for a guided model.\"\"\"\n",
    "    for function, arguments, keyword_arguments in pipeline_functions:\n",
    "        if keyword_arguments and (not arguments):\n",
    "            data = data.pipe(function, **keyword_arguments)\n",
    "        elif (not keyword_arguments) and (arguments):\n",
    "            data = data.pipe(function, *arguments)\n",
    "        else:\n",
    "            data = data.pipe(function)\n",
    "    X = data.drop(columns=[prediction_col]).to_numpy()\n",
    "    y = data.loc[:, prediction_col].to_numpy()\n",
    "    return X, y\n",
    "\n",
    "def select_columns(data, *columns):\n",
    "    \"\"\"Select only columns passed as arguments.\"\"\"\n",
    "    return data.loc[:, columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-southwest",
   "metadata": {},
   "source": [
    "## Step 2. Setup your `process_data_fm` function\n",
    "\n",
    "**Copy-paste your implementation of `process_data_fm` from question 8 of Homework 7 into the following cell.**\n",
    "\n",
    "Here are a few additional things **you should check and change to make sure your `process_data_fm` function satisfies**:\n",
    "- Unlike the homework, we will not be expecting your `process_data_fm` function to return both the design matrix `X` and the observed target vector `y`; your function should now **only return X**.\n",
    "- In addition, you **may NOT incorporate the `Sale Price` column in your feature engineering process** (so things such as removing outliers in Sale Price that would work for question 8 will no longer apply here anymore)\n",
    "- We understand that the original training and test data have a lot illegitimate prices that actually detract quite a bit from your model's performance. In order to help you focus on actually **engineering the best features and looking for patterns within your data**, we have prefiltered the data a bit more and removed those outliers in advance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-spain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please include all of your feature engineering process inside this function.\n",
    "# Do not modify the parameters of the function below. \n",
    "# Note that data will no longer have the column Sale Price in it directly, so plan your feature engineering process around that.\n",
    "def process_data_fm(data):\n",
    "    # Replace the following line with your own feature engineering pipeline\n",
    "    X = data\n",
    "    ...\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-funeral",
   "metadata": {},
   "source": [
    "## Step 3. Train your model\n",
    "\n",
    "Run the following cell to import the new set of training data to fit your model on. **No coding is required from you for this part**. If your `process_data_fm` satisfies all the specified requirements, the cell should run without any error.\n",
    "\n",
    "**As usual**, your model will predict the log-transformed sale price, and our autograder will handle transforming your predictions back to the normal vlaues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-whole",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('cook_county_contest_train.csv', index_col='Unnamed: 0')\n",
    "y_train = np.log(train_data['Sale Price'])\n",
    "train_data = train_data.drop(columns=['Sale Price'])\n",
    "X_train = process_data_fm(train_data)\n",
    "model = lm.LinearRegression(fit_intercept=True)\n",
    "model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attempted-cache",
   "metadata": {},
   "source": [
    "## Step 4. Make Predictions on the Test Dataset\n",
    "\n",
    "Run the following cell to estimate the sale price on the test dataset and export your model's predictions as a csv file called `predictions.csv`. Download the csv file from the same directory as the current notebook and submit it to the Gradescope assignment **Homework 7 - Build Your Own Model** and you should be able to see your model's rank from there!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-bridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('cook_county_contest_test.csv', index_col='Unnamed: 0')\n",
    "X_test = process_data_fm(test_data)\n",
    "y_test_predicted = model.predict(X_test)\n",
    "predictions = pd.DataFrame({'Sale Price': y_test_predicted})\n",
    "predictions.to_csv('predictions.csv')\n",
    "print('Your predictions have been exported as predictions.csv. Please download the file and submit it to Gradescope. ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
